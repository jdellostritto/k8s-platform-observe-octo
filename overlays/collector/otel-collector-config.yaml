receivers:
  otlp:
    protocols:
      grpc:

processors:
  # batch metrics before sending to reduce API usage
  batch:
    send_batch_max_size: 1000
    send_batch_size: 100
    timeout: 10s

exporters:
  prometheusremotewrite:
    endpoint: "http://base-prometheus:9090/api/v1/write"

  prometheus:
    endpoint: "0.0.0.0:8889"
    enable_open_metrics: true

  otlp/jaeger:
    endpoint: "http://base-jaeger:4317"
    tls:
      insecure: true

  zipkin:
    endpoint: http://base-zipkin:9411/api/v2/spans
    format: proto

  otlp/tempo:
    endpoint: "http://base-tempo:4317"
    tls:
      insecure: true

  loki:
    endpoint: "http://base-loki:3100/loki/api/v1/push"

service:
  pipelines:
    metrics:
      receivers: [otlp]
      processors: [batch]
      exporters: [prometheusremotewrite]
    traces:
      receivers: [otlp]
      processors: [batch]
      exporters: [otlp/jaeger,zipkin,otlp/tempo]
    logs:
      receivers: [otlp]
      processors: [batch]
      exporters: [loki]